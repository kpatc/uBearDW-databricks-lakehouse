# =============================================================================
# CONFIGURATION - uBear Data Warehouse
# =============================================================================
# Copier ce fichier vers config.env et remplir les valeurs

# =============================================================================
# 1. DATABRICKS WORKSPACE (OBLIGATOIRE)
# =============================================================================
DATABRICKS_HOST=https://adb-<workspace-id>.<region>.azuredatabricks.net
# Comment obtenir:
#   1. Ouvrir Databricks dans votre navigateur
#   2. Copier l'URL complète de la barre d'adresse
#   Exemples:
#     AWS:   https://dbc-xxxxx-yyyy.cloud.databricks.com
#     Azure: https://adb-123456789.12.azuredatabricks.net
#     GCP:   https://1234567890123456.7.gcp.databricks.com

DATABRICKS_TOKEN=dapi1234567890abcdef
# Comment obtenir:
#   1. Databricks UI → Cliquer sur votre nom (coin haut-droit) → "User Settings"
#   2. Onglet "Developer" ou "Access tokens"
#   3. "Generate new token"
#   4. Nom: "ubear-dw-deployment"
#   5. Durée: 90 jours
#   6. "Generate"
#   7. COPIER LE TOKEN (ne sera plus visible après)
# ⚠️ IMPORTANT: Ne JAMAIS commiter ce token dans Git !

# =============================================================================
# 2. KAFKA LOCAL (Docker Compose - Valeurs par défaut)
# =============================================================================
KAFKA_BOOTSTRAP_SERVERS=localhost:29092
# Pour connexion depuis votre machine vers Kafka dans Docker
# Port 29092 = connexions externes (depuis hôte)
# Port 9092 = connexions internes (entre containers)
# Défini dans docker-compose.yml ligne: KAFKA_ADVERTISED_LISTENERS

KAFKA_TOPIC_PREFIX=dbserver1.public
# Préfixe des topics Debezium: <server.name>.<database>.<table>
# "dbserver1" est défini dans local_stack/register_connector.sh

# =============================================================================
# 3. POSTGRESQL LOCAL (Docker Compose - Valeurs par défaut)
# =============================================================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=foodapp
POSTGRES_USER=foodapp
POSTGRES_PASSWORD=foodapp
# Ces valeurs sont dans docker-compose.yml section: services.postgres.environment

# =============================================================================
# 4. DATABRICKS CATALOG & SCHEMAS
# =============================================================================
CATALOG_NAME=ubear_catalog
# Si pas de Unity Catalog, utiliser: hive_metastore

SCHEMA_BRONZE=ubear_bronze
SCHEMA_SILVER=ubear_silver
SCHEMA_GOLD=ubear_gold
# Ces schémas seront créés automatiquement

# =============================================================================
# 5. DATABRICKS STORAGE
# =============================================================================
BRONZE_STORAGE_PATH=/dbfs/ubear/dlt/bronze
SILVER_STORAGE_PATH=/dbfs/ubear/dlt/silver
# Utilise DBFS par défaut (simple pour démarrer)
# Pour production, monter S3/Azure Blob/GCS:
#   Exemple: /mnt/datalake/ubear/dlt/bronze

# =============================================================================
# 6. DATABRICKS REPOS
# =============================================================================
DATABRICKS_REPO_PATH=/Repos/ubear-dw
# Comment configurer:
#   1. Databricks UI → "Repos" (menu gauche)
#   2. "Add Repo"
#   3. URL: https://github.com/kpatc/uBearDW-databricks-lakehouse
#   4. Provider: GitHub
#   5. Le chemin sera: /Repos/<votre-user>/uBearDW-databricks-lakehouse

# =============================================================================
# 7. DATABRICKS CLUSTER (Optionnel)
# =============================================================================
BATCH_CLUSTER_ID=
# Laisser vide pour créer un Job Cluster automatique (recommandé)
# Ou mettre l'ID d'un cluster existant:
#   Databricks UI → Compute → Copier l'ID depuis l'URL

CLUSTER_NODE_TYPE=i3.xlarge
# Type d'instance selon votre cloud:
#   AWS: i3.xlarge, i3.2xlarge, r5.xlarge
#   Azure: Standard_DS3_v2, Standard_DS4_v2
#   GCP: n1-highmem-4, n1-highmem-8

# =============================================================================
# 8. CONFIGURATION PIPELINES
# =============================================================================
BRONZE_MIN_WORKERS=2
BRONZE_MAX_WORKERS=8
SILVER_MIN_WORKERS=2
SILVER_MAX_WORKERS=10
# Autoscaling: ajusté automatiquement selon la charge

# =============================================================================
# 9. NOTIFICATIONS (Email pour alertes)
# =============================================================================
ALERT_EMAIL=votre-email@example.com
# Email pour recevoir les notifications des jobs
# Remplacer par votre email ou celui de l'équipe

# =============================================================================
# 10. ENVIRONNEMENT
# =============================================================================
ENVIRONMENT=development
# Valeurs: development, staging, production

# =============================================================================
# INSTRUCTIONS RAPIDES
# =============================================================================
# 
# DÉMARRAGE:
# ----------
# 1. Copier ce fichier: cp config.env.example config.env
# 2. Éditer config.env et remplir AU MINIMUM:
#    - DATABRICKS_HOST (votre URL Databricks)
#    - DATABRICKS_TOKEN (généré dans User Settings)
#    - ALERT_EMAIL (votre email)
# 3. Le reste peut garder les valeurs par défaut
#
# VÉRIFIER LA CONFIG:
# ------------------
# source config.env
# echo $DATABRICKS_HOST  # Doit afficher votre URL
#
# TESTER LA CONNEXION:
# --------------------
# databricks workspace list  # Doit lister vos notebooks
#
# SÉCURITÉ:
# ---------
# ⚠️ Ne JAMAIS commiter config.env dans Git (déjà dans .gitignore)
# ⚠️ Pour production, utiliser Databricks Secrets au lieu de fichiers .env
ENABLE_UNITY_CATALOG=true

# =============================================================================
# Development/Production
# =============================================================================
ENVIRONMENT=production
# Valeurs possibles: development, staging, production

# Development mode (plus de logging, pas de notifications)
DEV_MODE=false
